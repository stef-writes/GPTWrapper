
User Documentation Installation and Setup
Scriptchain is a custom tool, and its installation process or setup details aren't provided in the sample code. However, the example script shows usage of several Python libraries including os , langchain.llms , langchain.chains ,
langchain.document_loaders , langchain.indexes , and langchain.prompts . Make sure these libraries are installed and properly configured in your Python environment.
OrchestrateAI Documentation 2
API Key Setup
The OpenAI API key is required for the functionality of the Scriptchain tool. It's set up using the os library to set an environment variable. Replace "your-api- key" with your actual OpenAI API key.
Model Selection
Scriptchain allows you to select a language model for generating content. You can specify the desired language model from available options and set its parameters.
Corpus Indexing
Scriptchain allows you to load documents, split them into pages, and index them using PyPDFLoader , VectorstoreIndexCreator , and RetrievalQA from the
langchain library. Content Generation
Scriptchain can generate ideas based on a seed word or a context and guidance query. It can be customized manually or generated by the model.
Title, Description, and Tag Creation
With Scriptchain, you can create the title, description, and tags for your content using a LLMChain and a PromptTemplate .
Outline Generation
Scriptchain helps you identify the main points of your content and arrange them in a logical and coherent sequence.
Key Questions Generation
The tool can also generate key questions based on the subtopics of your content.
Paragraph Generation
Finally, Scriptchain allows you to generate paragraphs that address the key questions you've generated.

======================================================================================================================

Scriptchain Technical Guide
Scriptchain is a Python-based automation tool that leverages the power of natural language processing NLP and machine learning to generate content, perform tasks, and build digital products. It's designed to interact with both humans and other software tools, making it a flexible and versatile solution for a range of applications.
Key Components of Scriptchain
Here's a breakdown of the key components of Scriptchain:
OpenAI
Scriptchain utilizes OpenAI's language model to generate text-based content. It uses OpenAI's API to interact with the language model, giving it the ability to generate content for a variety of use cases.
Language Model Chains (LLMChain)
Scriptchain uses Language Model Chains LLMChain) to handle specific tasks. These are essentially pre-defined processes or scripts that the language model follows to generate content or perform a task. The LLMChain takes a prompt and uses the language model to generate an output. It can be customized to suit different tasks.
Prompts (PromptTemplate)
Prompts are used to instruct the language model on what to generate. A prompt is a string of text that the language model uses as a starting point when generating content. It can include variables that are replaced with specific data when the prompt is used.
RetrievalQA
OrchestrateAI Documentation 10
RetrievalQA is used to retrieve information from a specified source. It interacts with the Vectorstore index to find the most relevant information to a given query.
VectorstoreIndexCreator
VectorstoreIndexCreator is used to create an index of documents that can be queried to retrieve information. It converts the documents into a format that can be easily searched and retrieved.
PyPDFLoader
PyPDFLoader is a utility that loads and splits a PDF file into pages. It allows Scriptchain to process and analyze the contents of a PDF file.
Environment Variables
Scriptchain uses environment variables to store sensitive data like the OpenAI API key. This is a secure way to handle such data, as it's not hard-coded into the script and can be easily changed.
How Scriptchain Works
Here's a high-level overview of how Scriptchain works:
 Model Setup The desired language model from OpenAI is set up and configured with specific parameters like temperature, top_p, and max_tokens.
 Indexing The documents to be processed are loaded into the system and indexed using the VectorstoreIndexCreator. This creates a searchable index that can be queried to retrieve information.
 Query Generation Using the language model, a query is generated based on the given context. This query is used to retrieve relevant information from the index.
 Content Generation Using the retrieved information and the language model, content is generated. This includes titles, descriptions, tags, and other content as needed.
OrchestrateAI Documentation 11

 Sequencing and Ordering The generated content is arranged into a logical and coherent sequence.



======================================================================================================================

Model Selection
Scriptchain allows you to select a language model for generating content. This can be done as follows:
You can specify the desired language model from available options and set its parameters. In the provided script, a temperature of 0.9 is set. The temperature parameter in language models affects the randomness of the output. A higher temperature results in more random outputs, while a lower temperature makes the output more deterministic.
Corpus Indexing
Scriptchain allows you to load documents, split them into pages, and index them. This can be done using PyPDFLoader , VectorstoreIndexCreator , and
RetrievalQA from the langchain library:
 os.environ["OPENAI_API_KEY"] = "your-api-key"
from langchain.llms import OpenAI
model = OpenAI(temperature=0.9)
from langchain.document_loaders import PyPDFLoader
from langchain.indexes import VectorstoreIndexCreator
from langchain.chains import RetrievalQA
OrchestrateAI Documentation 6
 loader = PyPDFLoader("document.pdf")
pages = loader.load_and_split()
index = VectorstoreIndexCreator().from_loaders([loader])
retreiver = index.vectorstore.as_retriever()
Idea Generation
Scriptchain can generate ideas based on a seed word or a context and guidance query. It can be customized manually or generated by the model:
 context_and_guidance_query = "Generate a youtube script ide
a. Provide sufficient context about the purpose of the scri
pt and the desired tone of the video."
context_and_guidance = index.query(context_and_guidance_que
ry)
Title, Description, and Tag Creation
With Scriptchain, you can create the title, description, and tags for your content using a LLMChain and a PromptTemplate :
   from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
title_prompt = PromptTemplate(
    input_variables=["context"],
    template= "Respond with an emotional, provocative, and
intriguing title for the following youtube video. Here is t
he context: '{context}'"
)
title_chain = LLMChain(llm=model, prompt = title_prompt, ou
tput_key = "title")
OrchestrateAI Documentation 7

 saved_title = title_chain({"context":context_and_guidance})
["title"]
You can create similar chains for descriptions and tags.
Outline Generation
Scriptchain helps you identify the main points of your content and arrange them in a logical and coherent sequence:
 main_points = index.query("Tell me all the main ideas regar
ding this context: " + context_and_guidance)
sequence_chain = LLMChain(llm=model, prompt = sequence_prom
pt, output_key = "outline")
saved_sequencing_outline = sequence_chain({"main_points":ma
in_points})["outline"]
Key Questions Generation
The tool can also generate key questions based on the subtopics of your content:
 question_prompt = PromptTemplate(
    input_variables=["subtopic"],
    template= "Write a few key questions based on the follo
wing topic. Here is the topic you are to write questions fo
r: '{subtopic}'"
)
question_chain = LLMChain(llm=model, prompt = question_prom
pt, output_key = "questions")
question_list = []
for subtopic in logical_sequence:
    questions = [q.strip() for q in question_chain({"subtop
OrchestrateAI Documentation 8

ic":subtopic})["questions"].split("~") if len(q) > 4]
    question_list.extend((questions))
Paragraph Generation
Finally, Scriptchain allows you to generate paragraphs that address the key questions you've generated:
paragraph_prompt = PromptTemplate(
    input_variables=["question", "prev_paragraph"],
    template= "You are helping me with a youtube script. Yo
u are to write a long intriguing, emotional, and provocativ
e paragraph that addresses the following question: '{questi
on}'. Here is the previous paragraph for context: '{prev_pa
ragraph}'"
)
paragraph_chain = LLMChain(llm=model, prompt = paragraph_pr
ompt, output_key = "paragraph")
list_of_paragraphs = []
for i, question in enumerate(question_list):
    if i > 0:
        list_of_paragraphs.append(paragraph_chain({"questio
n":question, "prev_paragraph":list_of_paragraphs[i-1]})["pa
ragraph"])
    else:
        list_of_paragraphs.append(paragraph_chain({"questio
n":question, "prev_paragraph":''})["paragraph"])
This results in a list of paragraphs that constitute the body of your content.

======================================================================================================================


# --- Example Usage ---
@app.post("/generate_horror_story")
def generate_horror_story(premise: str):
    """Example endpoint that creates a horror story workflow."""
    # Reset the script chain
    new_chain = ScriptChain()
    new_chain.add_callback(LoggingCallback())

    # Configure the model
    story_config = LLMConfig(model="gpt-3.5-turbo", temperature=1.0)

    # Add nodes for the horror story generation
    new_chain.add_node(
        "premise",
        "text_generation",
        input_keys=[],
        output_keys=["premise"],
        model_config=story_config
    )

    new_chain.add_node(
        "characters",
        "text_generation",
        input_keys=["premise"],
        output_keys=["characters"],
        model_config=story_config
    )

    new_chain.add_node(
        "story_outline",
        "text_generation",
        input_keys=["premise", "characters"],
        output_keys=["story_outline"],
        model_config=story_config
    )

    # Connect the nodes
    new_chain.add_edge("premise", "characters")
    new_chain.add_edge("characters", "story_outline")

    # Store the premise
    new_chain.storage["premise"] = premise

    # Execute the chain
    results = new_chain.execute()

    return results

# --- Run API Server ---
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)